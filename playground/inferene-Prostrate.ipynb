{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "from trainprostVQBMCtoRUN import Net as QNet\n",
    "from trainprostunetBMCtoRUM import Net as Net\n",
    "from skimage.util import random_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load('/vol/biomedic2/agk21/PhDLogs/codes/Vector-Quantisation-for-Robust-Segmentation/Logs/outputprostatefinal/outputprostatefinal/unetBMCtoRUM/best_metric_model-v1.ckpt')['state_dict'])\n",
    "net = net.eval()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 13940.12it/s]\n",
      "Loading Data: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 7590.13it/s]\n",
      "Loading Data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 17351.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train:  25\n",
      "#val:    5\n",
      "#test:   25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from trainprostVQBMCtoRUN import ProstateDataModule\n",
    "loader = ProstateDataModule(\n",
    "            batch_size=1,\n",
    "            num_workers=4,\n",
    "            csv_train_img=\"/vol/biomedic3/as217/vqseg/ProstateDomain/Prostatedomaintr1.csv\",\n",
    "            csv_val_img=\"/vol/biomedic3/as217/vqseg/ProstateDomain/ProstatedomainvalBMC1.csv\",\n",
    "            csv_test_img=\"/vol/biomedic3/as217/vqseg/ProstateDomain/Prostatedomaints1.csv\",\n",
    "        )\n",
    "\n",
    "val_dataloader = loader.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy(noise_typ, image, weightage = 0.0):\n",
    "    if noise_typ == \"gauss\":\n",
    "        mean = 0\n",
    "        var = 1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean, sigma,image.shape)\n",
    "        gauss = gauss.reshape(*image.shape)\n",
    "        noisy = image + weightage*gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        s_vs_p = 0.5\n",
    "        amount = weightage\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape[-3:]]\n",
    "        for x, y, z in zip(*coords):\n",
    "            out[0, 0, x, y, z] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape[-3:]]\n",
    "        for x, y, z in zip(*coords):\n",
    "            out[0, 0, x, y, z] = 0\n",
    "            \n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(weightage * image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        gauss = np.random.randn(*image.shape)\n",
    "        gauss = gauss.reshape(*image.shape)        \n",
    "        noisy = image + weightage*image * gauss\n",
    "        return noisy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def generate_TTA_results(name, data, noise_type='gauss', base_path='.'):\n",
    "    nTTAs = 100\n",
    "    zdata = {}\n",
    "    \n",
    "    assert noise_type in ['gauss', 's&p', 'poisson', 'speckle'], 'invalid noise_type'\n",
    "    \n",
    "    noise_threshold_list = [0.0, 0.01, 0.1, 0.5, 0.75]\n",
    "    \n",
    "    for noise_threshold in noise_threshold_list:\n",
    "        embs = []; recons = []\n",
    "        for _ in range(nTTAs):\n",
    "            x = data['image'][:1, ...].numpy()\n",
    "            dtype = data['image'].dtype\n",
    "            x = noisy(noise_type, x, noise_threshold)\n",
    "            x = torch.tensor(x).type(dtype).cuda() \n",
    "            with torch.no_grad():\n",
    "                x, encoding = net._model(x)\n",
    "            embs.append(encoding)\n",
    "            recons.append(x)\n",
    "\n",
    "        embs = torch.cat(embs, 0)\n",
    "        recons = torch.cat(recons, 0)\n",
    "        recons = torch.argmax(recons, 1)\n",
    "        \n",
    "        zdata[noise_threshold] = {'emb': embs.cpu().numpy(), \n",
    "                                      'recon': recons.cpu().squeeze().numpy(), \n",
    "                                      'img': data['image'][:1, ...].squeeze().numpy(), \n",
    "                                      'label': data['label'][:1, ...].squeeze().numpy()}\n",
    "\n",
    "    base_path = os.path.join(base_path, noise_type)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    with open(os.path.join(base_path,'{}.pickle'.format(name)), 'wb') as file:\n",
    "        pickle.dump(zdata, file)\n",
    "    return zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                         | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case25.nii.gz\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case25_Segmentation.nii.gz\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case26.nii.gz\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case28.nii.gz\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case26_Segmentation.nii.gz\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case28_Segmentation.nii.gz\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                         | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "\n",
      "=== Transform input info -- LoadImaged ===\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case29.nii.gz\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case29.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case29_Segmentation.nii.gz\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case29_Segmentation.nii.gz\n",
      "image statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case27.nii.gz\n",
      "label statistics:\n",
      "Type: <class 'str'> None\n",
      "Value: /vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case27_Segmentation.nii.gz\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/nibabel/loadsave.py\", line 42, in load\n    stat_result = os.stat(filename)\nPermissionError: [Errno 13] Permission denied: '/vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case25.nii.gz'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/transform.py\", line 82, in apply_transform\n    return _apply_transform(transform, data, unpack_items)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/transform.py\", line 53, in _apply_transform\n    return transform(parameters)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/io/dictionary.py\", line 121, in __call__\n    data = self._loader(d[key], reader)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/io/array.py\", line 194, in __call__\n    img = reader.read(filename)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/data/image_reader.py\", line 383, in read\n    img = nib.load(name, **kwargs_)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/nibabel/loadsave.py\", line 44, in load\n    raise FileNotFoundError(f\"No such file or no access: '{filename}'\")\nFileNotFoundError: No such file or no access: '/vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case25.nii.gz'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"../trainprostVQBMCtoRUN.py\", line 185, in __getitem__\n    sample = self.get_sample(item)\n  File \"../trainprostVQBMCtoRUN.py\", line 197, in get_sample\n    sample = self.val_transforms(sample)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/compose.py\", line 160, in __call__\n    input_ = apply_transform(_transform, input_, self.map_items, self.unpack_items)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/transform.py\", line 106, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7fa97043bba8>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2366185/34416378.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_zdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mall_zdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mall_zdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gauss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_TTA_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gauss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PRST/UNet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/nibabel/loadsave.py\", line 42, in load\n    stat_result = os.stat(filename)\nPermissionError: [Errno 13] Permission denied: '/vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case25.nii.gz'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/transform.py\", line 82, in apply_transform\n    return _apply_transform(transform, data, unpack_items)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/transform.py\", line 53, in _apply_transform\n    return transform(parameters)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/io/dictionary.py\", line 121, in __call__\n    data = self._loader(d[key], reader)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/io/array.py\", line 194, in __call__\n    img = reader.read(filename)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/data/image_reader.py\", line 383, in read\n    img = nib.load(name, **kwargs_)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/nibabel/loadsave.py\", line 44, in load\n    raise FileNotFoundError(f\"No such file or no access: '{filename}'\")\nFileNotFoundError: No such file or no access: '/vol/biomedic3/as217/vqseg/ProstateDomain/BMC/Case25.nii.gz'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"../trainprostVQBMCtoRUN.py\", line 185, in __getitem__\n    sample = self.get_sample(item)\n  File \"../trainprostVQBMCtoRUN.py\", line 197, in get_sample\n    sample = self.val_transforms(sample)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/compose.py\", line 160, in __call__\n    input_ = apply_transform(_transform, input_, self.map_items, self.unpack_items)\n  File \"/vol/biomedic2/agk21/anaconda3/envs/quantization/lib/python3.7/site-packages/monai/transforms/transform.py\", line 106, in apply_transform\n    raise RuntimeError(f\"applying transform {transform}\") from e\nRuntimeError: applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7fa97043bba8>\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_zdata = {}\n",
    "for i in tqdm(range(100)):\n",
    "    data = next(iter(val_dataloader))\n",
    "    all_zdata[i] = {}\n",
    "    all_zdata[i]['gauss'] = generate_TTA_results('image{}'.format(i), data, 'gauss', 'PRST/UNet')\n",
    "    all_zdata[i]['s&p'] = generate_TTA_results('image{}'.format(i), data, 's&p', 'PRST/UNet')\n",
    "    all_zdata[i]['poisson'] = generate_TTA_results('image{}'.format(i), data, 'poisson', 'PRST/UNet')\n",
    "    all_zdata[i]['speckle'] = generate_TTA_results('image{}'.format(i), data, 'speckle', 'PRST/UNet')\n",
    "    \n",
    "with open('all_data_PRST_UNet.pickle', 'wb') as file:\n",
    "    pickle.dump(all_zdata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qnet = QNet()\n",
    "qnet.load_state_dict(torch.load('/vol/biomedic2/agk21/PhDLogs/codes/Vector-Quantisation-for-Robust-Segmentation/Logs/outputprostatefinal/outputprostatefinal/vqBCMtoRUM/best_metric_model-v1.ckpt')['state_dict'])\n",
    "qnet = qnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def VQgenerate_TTA_results(name, data, noise_type='gauss', base_path='.'):\n",
    "    nTTAs = 100\n",
    "    zdata = {}\n",
    "    \n",
    "    assert noise_type in ['gauss', 's&p', 'poisson', 'speckle'], 'invalid noise_type'\n",
    "    \n",
    "    noise_threshold_list = [0.0, 0.01, 0.1, 0.5, 0.75]\n",
    "    \n",
    "    for noise_threshold in noise_threshold_list:\n",
    "        embs = []; recons = []; emb_losses = []\n",
    "        for _ in range(nTTAs):\n",
    "            x = data['image'][:1, ...].numpy()\n",
    "            dtype = data['image'].dtype\n",
    "            x = noisy(noise_type, x, noise_threshold)\n",
    "            x = torch.tensor(x).type(dtype).cuda() \n",
    "            with torch.no_grad():\n",
    "                x, emb_loss, encoding = qnet._model(x)\n",
    "            embs.append(encoding)\n",
    "            recons.append(x)\n",
    "            emb_losses.append(emb_loss)\n",
    "\n",
    "        embs = torch.cat(embs, 0)\n",
    "        emb_losses = torch.cat(emb_losses, 0)\n",
    "        recons = torch.cat(recons, 0)\n",
    "        recons = torch.argmax(recons, 1)\n",
    "        \n",
    "        zdata[noise_threshold] = {'emb': embs.cpu().numpy(),\n",
    "                                      'emb_loss': emb_losses.cpu().numpy(),\n",
    "                                      'recon': recons.cpu().squeeze().numpy(), \n",
    "                                      'img': data['image'][:1, ...].squeeze().numpy(), \n",
    "                                      'label': data['label'][:1, ...].squeeze().numpy()}\n",
    "\n",
    "    base_path = os.path.join(base_path, noise_type)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    with open(os.path.join(base_path,'{}.pickle'.format(name)), 'wb') as file:\n",
    "        pickle.dump(zdata, file)\n",
    "    return zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_zqdata = {}\n",
    "for i in tqdm(range(100)):\n",
    "    data = next(iter(val_dataloader))\n",
    "    all_zqdata[i] = {}\n",
    "    all_zqdata[i]['gauss'] = VQgenerate_TTA_results('image{}'.format(i), data, 'gauss', 'PRST/VQNet')\n",
    "    all_zqdata[i]['s&p'] = VQgenerate_TTA_results('image{}'.format(i), data, 's&p', 'PRST/VQNet')\n",
    "    all_zqdata[i]['poisson'] = VQgenerate_TTA_results('image{}'.format(i), data, 'poisson', 'PRST/VQNet')\n",
    "    all_zqdata[i]['speckle'] = VQgenerate_TTA_results('image{}'.format(i), data, 'speckle', 'PRST/VQNet')\n",
    "    \n",
    "with open('all_data_PRST_VQNet.pickle', 'wb') as file:\n",
    "        pickle.dump(all_zqdata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zqdata[0.01]['emb'].shape, zdata[0.01]['emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for noise_threshold in noise_threshold_list:\n",
    "    print (\"============================ noise: {} ===========\".format(noise_threshold))\n",
    "    z, zq = zdata[noise_threshold]['emb'], zqdata[noise_threshold]['emb']\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 0,0,0], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 0,0,0], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 1, 1], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 1, 1], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 0, 1], cmap='coolwarm')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 0, 1], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 0, 0], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 0, 0], cmap='coolwarm')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dice = lambda p, l: np.mean([2*(p == i)*(l == i)/((p==i) + (l ==i) + 1e-3) for i in np.unique(l)])\n",
    "import pandas as pd\n",
    "\n",
    "def _draw_(dict_info, noise_type='gauss', base_dir= '.'):\n",
    "    nimgs = len(dict_info.keys())\n",
    "    test_ = dict_info[0][noise_type]\n",
    "    noise_threshold_list = list(test_.keys())\n",
    "    \n",
    "    test_embs = test_[noise_threshold_list[0]]['emb'] # nttas, ...\n",
    "    nttas = test_embs.shape[0]\n",
    "    z_dim = np.prod(test_embs.shape[1:])\n",
    "    \n",
    "    \n",
    "    dice_scores_x = []\n",
    "    dice_scores_y = []\n",
    "    categories = []\n",
    "    \n",
    "    for ni, noise_threshold in enumerate(noise_threshold_list):\n",
    "        \n",
    "            \n",
    "        result_img = np.zeros((nimgs, z_dim))\n",
    "        \n",
    "        for iimg in range(nimgs):\n",
    "            z = dict_info[iimg][noise_type][noise_threshold]['emb'].reshape(nttas, -1)\n",
    "            z = (z - z.min())/(z.max() - z.min())\n",
    "            \n",
    "            result_img[iimgs, :] = np.var(z, axis=0).T\n",
    "            \n",
    "            if noise_threshold == 0.0:\n",
    "                dice_scores_x.append(np.mean([mean_dice(dict_info[iimg][noise_type][noise_threshold]['recon'][itta, ...], \n",
    "                                                    dict_info[iimg][noise_type][noise_threshold]['label']) \\\n",
    "                                                      for itta in range(nttas)]))\n",
    "            else:\n",
    "                dice_scores_y.append(np.mean([mean_dice(dict_info[iimg][noise_type][noise_threshold]['recon'][itta, ...], \n",
    "                                                    dict_info[iimg][noise_type][noise_threshold]['label']) \\\n",
    "                                                      for itta in range(nttas)]))\n",
    "                \n",
    "                categories.append('Noise Threshold: {}'.format(noise_threshold))\n",
    "                \n",
    "        \n",
    "        base_path = os.path.join(base_path, noise_type)\n",
    "        base_path = os.path.join(base_path, 'plots')\n",
    "        os.makedirs(base_path, exist_ok=True)\n",
    "        \n",
    "        plt.figure(figsize=(1, 10))\n",
    "        plt.imshow(result_img, cmap='coolwarm', vmin=0, vmax=1)\n",
    "        plt.axis (‘off’)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(base_path, 'NoiseT{}_NoiseType{}.png'.format(noise_threshold, noise_type)))\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    df['actual-dice'] = dice_scores_x * (len(noise_threshold_list) - 2)\n",
    "    df['perturbed- dice'] = dice_scores_y\n",
    "    df['categories'] = categories\n",
    "\n",
    "    p = sns.jointplot(data=df, x='actual-dice', y='perturbed- dice',  hue=\"categories\", alpha=0.5)\n",
    "    p.plot_joint(sns.kdeplot, levels=20)\n",
    "    p.fig.suptitle(\"aligned latent vectors\")\n",
    "    p.fig.tight_layout()\n",
    "    p.fig.subplots_adjust(top=0.95)\n",
    "    plt.savefig(os.path.join(base_path, 'dice_score_distribution_{}.png'.format(noise_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_data_ABDCT_UNet.pickle', 'rb') as file:\n",
    "    dict_info = pickle.load(file)\n",
    "    \n",
    "_draw_(dict_info, 'gauss', 'PRST/VQNet')\n",
    "_draw_(dict_info, 's&p', 'PRST/VQNet')\n",
    "_draw_(dict_info, 'poisson', 'PRST/VQNet')\n",
    "_draw_(dict_info, 'speckle', 'PRST/VQNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_data_ABDCT_VQNet.pickle', 'rb') as file:\n",
    "    dict_info = pickle.load(file)\n",
    "    \n",
    "_draw_(dict_info, 'gauss', 'PRST/VQNet')\n",
    "_draw_(dict_info, 's&p', 'PRST/VQNet')\n",
    "_draw_(dict_info, 'poisson', 'PRST/VQNet')\n",
    "_draw_(dict_info, 'speckle', 'PRST/VQNet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
