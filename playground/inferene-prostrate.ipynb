{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.0\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.10.2+cu102\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 714d00dffe6653e21260160666c4c201ab66511b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.1\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.4.0\n",
      "gdown version: 4.2.1\n",
      "TorchVision version: 0.8.2\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.4.0\n",
      "transformers version: 4.16.2\n",
      "mlflow version: 1.23.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "/tmp/tmpji5xxeg0\n",
      "MONAI version: 0.8.0\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.10.2+cu102\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 714d00dffe6653e21260160666c4c201ab66511b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.1\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.4.0\n",
      "gdown version: 4.2.1\n",
      "TorchVision version: 0.8.2\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.4.0\n",
      "transformers version: 4.16.2\n",
      "mlflow version: 1.23.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "/tmp/tmpzs0jeenu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "from VQUnet3D import Net as QNet\n",
    "from Unet3D import Net as Net\n",
    "from skimage.util import random_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(fold=0)\n",
    "net.load_state_dict(torch.load('/vol/biomedic2/agk21/PhDLogs/codes/Vector-Quantisation-for-Robust-Segmentation/Logs/output4/disease1/vqseg1/version_1/checkpoints/epoch=289-step=6959.ckpt')['state_dict'])\n",
    "net = net.eval()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 19/24 [00:51<00:10,  2.14s/it]"
     ]
    }
   ],
   "source": [
    "from Unet3D import Data\n",
    "loader = Data(fold=0,numfolds=5, size = (32, 32, 32))\n",
    "val_dataloader = loader.val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy(noise_typ, image, weightage = 0.0):\n",
    "    if noise_typ == \"gauss\":\n",
    "        mean = 0\n",
    "        var = 1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean, sigma,image.shape)\n",
    "        gauss = gauss.reshape(*image.shape)\n",
    "        noisy = image + weightage*gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        s_vs_p = 0.5\n",
    "        amount = weightage\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape[-3:]]\n",
    "        for x, y, z in zip(*coords):\n",
    "            out[0, 0, x, y, z] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape[-3:]]\n",
    "        for x, y, z in zip(*coords):\n",
    "            out[0, 0, x, y, z] = 0\n",
    "            \n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(weightage * image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        gauss = np.random.randn(*image.shape)\n",
    "        gauss = gauss.reshape(*image.shape)        \n",
    "        noisy = image + weightage*image * gauss\n",
    "        return noisy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def generate_TTA_results(name, data, noise_type='gauss', base_path='.'):\n",
    "    nTTAs = 100\n",
    "    zdata = {}\n",
    "    \n",
    "    assert noise_type in ['gauss', 's&p', 'poisson', 'speckle'], 'invalid noise_type'\n",
    "    \n",
    "    noise_threshold_list = [0.01, 0.1, 0.5, 0.75, 0.9]\n",
    "    \n",
    "    for noise_threshold in noise_threshold_list:\n",
    "        embs = []; recons = []\n",
    "        for _ in range(nTTAs):\n",
    "            x = data['image'][:1, ...].numpy()\n",
    "            dtype = data['image'].dtype\n",
    "            x = noisy(noise_type, x, noise_threshold)\n",
    "            x = torch.tensor(x).type(dtype).cuda() \n",
    "            with torch.no_grad():\n",
    "                x, encoding = net._model(x)\n",
    "            embs.append(encoding)\n",
    "            recons.append(x)\n",
    "\n",
    "        embs = torch.cat(embs, 0)\n",
    "        recons = torch.cat(recons, 0)\n",
    "        recons = torch.argmax(recons, 1)\n",
    "        \n",
    "        zdata[noise_threshold] = {'emb': embs.cpu().numpy(), \n",
    "                                      'recon': recons.cpu().squeeze().numpy(), \n",
    "                                      'img': data['image'][:1, ...].squeeze().numpy(), \n",
    "                                      'label': data['label'][:1, ...].squeeze().numpy()}\n",
    "\n",
    "    base_path = os.path.join(base_path, noise_type)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    with open(os.path.join(base_path,'{}.pickle'.format(name)), 'wb') as file:\n",
    "        pickle.dump(zdata, file)\n",
    "    return zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_zdata = {}\n",
    "for i in tqdm(range(100)):\n",
    "    data = next(iter(val_dataloader))\n",
    "    all_zdata[i] = {}\n",
    "    all_zdata[i]['gauss'] = generate_TTA_results('image{}'.format(i), data, 'gauss', 'ABDCT/UNet')\n",
    "    all_zdata[i]['s&p'] = generate_TTA_results('image{}'.format(i), data, 's&p', 'ABDCT/UNet')\n",
    "    all_zdata[i]['poisson'] = generate_TTA_results('image{}'.format(i), data, 'poisson', 'ABDCT/UNet')\n",
    "    all_zdata[i]['speckle'] = generate_TTA_results('image{}'.format(i), data, 'speckle', 'ABDCT/UNet')\n",
    "    \n",
    "with open('all_data_ABDCT_UNet.pickle', 'wb') as file:\n",
    "    pickle.dump(all_zdata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qnet = QNet()\n",
    "qnet.load_state_dict(torch.load('/vol/biomedic2/agk21/PhDLogs/codes/Vector-Quantisation-for-Robust-Segmentation/Logs/output4/disease1/vqseg/version_1/checkpoints/epoch=294-step=7079.ckpt')['state_dict'])\n",
    "qnet = qnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def VQgenerate_TTA_results(name, data, noise_type='gauss', base_path='.'):\n",
    "    nTTAs = 100\n",
    "    zdata = {}\n",
    "    \n",
    "    assert noise_type in ['gauss', 's&p', 'poisson', 'speckle'], 'invalid noise_type'\n",
    "    \n",
    "    noise_threshold_list = [0.01, 0.1, 0.5, 0.75, 0.9]\n",
    "    \n",
    "    for noise_threshold in noise_threshold_list:\n",
    "        embs = []; recons = []; emb_losses = []\n",
    "        for _ in range(nTTAs):\n",
    "            x = data['image'][:1, ...].numpy()\n",
    "            dtype = data['image'].dtype\n",
    "            x = noisy(noise_type, x, noise_threshold)\n",
    "            x = torch.tensor(x).type(dtype).cuda() \n",
    "            with torch.no_grad():\n",
    "                x, emb_loss, encoding = qnet._model(x)\n",
    "            embs.append(encoding)\n",
    "            recons.append(x)\n",
    "            emb_losses.append(emb_loss)\n",
    "\n",
    "        embs = torch.cat(embs, 0)\n",
    "        emb_losses = torch.cat(emb_losses, 0)\n",
    "        recons = torch.cat(recons, 0)\n",
    "        recons = torch.argmax(recons, 1)\n",
    "        \n",
    "        zdata[noise_threshold] = {'emb': embs.cpu().numpy(),\n",
    "                                      'emb_loss': emb_losses.cpu().numpy(),\n",
    "                                      'recon': recons.cpu().squeeze().numpy(), \n",
    "                                      'img': data['image'][:1, ...].squeeze().numpy(), \n",
    "                                      'label': data['label'][:1, ...].squeeze().numpy()}\n",
    "\n",
    "    base_path = os.path.join(base_path, noise_type)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    with open(os.path.join(base_path,'{}.pickle'.format(name)), 'wb') as file:\n",
    "        pickle.dump(zdata, file)\n",
    "    return zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_zqdata = {}\n",
    "for i in tqdm(range(100)):\n",
    "    data = next(iter(val_dataloader))\n",
    "    all_zqdata[i] = {}\n",
    "    all_zqdata[i]['gauss'] = VQgenerate_TTA_results('image{}'.format(i), data, 'gauss', 'ABDCT/VQNet')\n",
    "    all_zqdata[i]['s&p'] = VQgenerate_TTA_results('image{}'.format(i), data, 's&p', 'ABDCT/VQNet')\n",
    "    all_zqdata[i]['poisson'] = VQgenerate_TTA_results('image{}'.format(i), data, 'poisson', 'ABDCT/VQNet')\n",
    "    all_zqdata[i]['speckle'] = VQgenerate_TTA_results('image{}'.format(i), data, 'speckle', 'ABDCT/VQNet')\n",
    "    \n",
    "with open('all_data_ABDCT_VQNet.pickle', 'wb') as file:\n",
    "        pickle.dump(all_zqdata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zqdata[0.01]['emb'].shape, zdata[0.01]['emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ noise: 0.01 ===========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'zqdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2124816/1755847373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnoise_threshold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoise_threshold_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"============================ noise: {} ===========\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise_threshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzqdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise_threshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'zqdata' is not defined"
     ]
    }
   ],
   "source": [
    "for noise_threshold in noise_threshold_list:\n",
    "    print (\"============================ noise: {} ===========\".format(noise_threshold))\n",
    "    z, zq = zdata[noise_threshold]['emb'], zqdata[noise_threshold]['emb']\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 0,0,0], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 0,0,0], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 1, 1], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 1, 1], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 0, 1], cmap='coolwarm')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 0, 1], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 0, 0], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 0, 0], cmap='coolwarm')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_threshold in noise_threshold_list:\n",
    "    print (\"============================ noise: {} ===========\".format(noise_threshold))\n",
    "    z, zq = zdata[noise_threshold]['emb'].reshape(100, 256, -1), zqdata[noise_threshold]['emb'].reshape(100, 256, -1)\n",
    "    \n",
    "    maxZ = np.max(z, axis=0).T\n",
    "    z = (z - z.min())/(z.max() - z.min())\n",
    "    zq = (zq - zq.min())/(zq.max() - zq.min())\n",
    "    \n",
    "    plt.figure(figsize=(50, 5))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(np.var(z, axis=0).T, cmap='coolwarm', vmin=0, vmax=1)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(np.var(zq, axis=0).T, cmap='coolwarm', vmin=0, vmax=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
