{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.8.0\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.10.2+cu102\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 714d00dffe6653e21260160666c4c201ab66511b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.1\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.4.0\n",
      "gdown version: 4.2.1\n",
      "TorchVision version: 0.8.2\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.4.0\n",
      "transformers version: 4.16.2\n",
      "mlflow version: 1.23.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "/tmp/tmpgqjvtmvc\n",
      "MONAI version: 0.8.0\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.10.2+cu102\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 714d00dffe6653e21260160666c4c201ab66511b\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.6\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.1\n",
      "Pillow version: 8.4.0\n",
      "Tensorboard version: 2.4.0\n",
      "gdown version: 4.2.1\n",
      "TorchVision version: 0.8.2\n",
      "tqdm version: 4.62.3\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.3.5\n",
      "einops version: 0.4.0\n",
      "transformers version: 4.16.2\n",
      "mlflow version: 1.23.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "/tmp/tmpied4fnd8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "\n",
    "from VQUnet3D import Net as QNet\n",
    "from Unet3D import Net as Net\n",
    "from skimage.util import random_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(fold=0)\n",
    "net.load_state_dict(torch.load('/vol/biomedic2/agk21/PhDLogs/codes/Vector-Quantisation-for-Robust-Segmentation/Logs/output4/disease1/vqseg1/version_1/checkpoints/epoch=289-step=6959.ckpt')['state_dict'])\n",
    "net = net.eval()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [01:06<00:00,  2.79s/it]\n",
      "Loading dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:17<00:00,  2.92s/it]\n"
     ]
    }
   ],
   "source": [
    "from Unet3D import Data\n",
    "loader = Data(fold=0,numfolds=5, size = (32, 32, 32))\n",
    "val_dataloader = loader.val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy(noise_typ, image, weightage = 0.0):\n",
    "    if noise_typ == \"gauss\":\n",
    "        mean = 0\n",
    "        var = 1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean, sigma,image.shape)\n",
    "        gauss = gauss.reshape(*image.shape)\n",
    "        noisy = image + weightage*gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        s_vs_p = 0.5\n",
    "        amount = weightage\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape[-3:]]\n",
    "        for x, y, z in zip(*coords):\n",
    "            out[0, 0, x, y, z] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape[-3:]]\n",
    "        for x, y, z in zip(*coords):\n",
    "            out[0, 0, x, y, z] = 0\n",
    "            \n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(weightage * image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        gauss = np.random.randn(*image.shape)\n",
    "        gauss = gauss.reshape(*image.shape)        \n",
    "        noisy = image + weightage*image * gauss\n",
    "        return noisy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def generate_TTA_results(name, data, noise_type='gauss', base_path='.'):\n",
    "    nTTAs = 100\n",
    "    zdata = {}\n",
    "    \n",
    "    assert noise_type in ['gauss', 's&p', 'poisson', 'speckle'], 'invalid noise_type'\n",
    "    \n",
    "    noise_threshold_list = [0.0, 0.01, 0.1, 0.5, 0.75]\n",
    "    \n",
    "    for noise_threshold in noise_threshold_list:\n",
    "        embs = []; recons = []\n",
    "        for _ in range(nTTAs):\n",
    "            x = data['image'][:1, ...].numpy()\n",
    "            dtype = data['image'].dtype\n",
    "            x = noisy(noise_type, x, noise_threshold)\n",
    "            x = torch.tensor(x).type(dtype).cuda() \n",
    "            with torch.no_grad():\n",
    "                x, encoding = net._model(x)\n",
    "            embs.append(encoding)\n",
    "            recons.append(x)\n",
    "\n",
    "        embs = torch.cat(embs, 0)\n",
    "        recons = torch.cat(recons, 0)\n",
    "        recons = torch.argmax(recons, 1)\n",
    "        \n",
    "        zdata[noise_threshold] = {'emb': embs.cpu().numpy(), \n",
    "                                      'recon': recons.cpu().squeeze().numpy(), \n",
    "                                      'img': data['image'][:1, ...].squeeze().numpy(), \n",
    "                                      'label': data['label'][:1, ...].squeeze().numpy()}\n",
    "\n",
    "    base_path = os.path.join(base_path, noise_type)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    with open(os.path.join(base_path,'{}.pickle'.format(name)), 'wb') as file:\n",
    "        pickle.dump(zdata, file)\n",
    "    return zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████████████████▉                                                                                                                 | 28/100 [54:28<2:34:13, 128.52s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_zdata = {}\n",
    "for i in tqdm(range(100)):\n",
    "    data = next(iter(val_dataloader))\n",
    "    all_zdata[i] = {}\n",
    "    all_zdata[i]['gauss'] = generate_TTA_results('image{}'.format(i), data, 'gauss', 'ABDCT/UNet')\n",
    "    all_zdata[i]['s&p'] = generate_TTA_results('image{}'.format(i), data, 's&p', 'ABDCT/UNet')\n",
    "    all_zdata[i]['poisson'] = generate_TTA_results('image{}'.format(i), data, 'poisson', 'ABDCT/UNet')\n",
    "    all_zdata[i]['speckle'] = generate_TTA_results('image{}'.format(i), data, 'speckle', 'ABDCT/UNet')\n",
    "    \n",
    "with open('all_data_ABDCT_UNet.pickle', 'wb') as file:\n",
    "    pickle.dump(all_zdata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qnet = QNet()\n",
    "qnet.load_state_dict(torch.load('/vol/biomedic2/agk21/PhDLogs/codes/Vector-Quantisation-for-Robust-Segmentation/Logs/output4/disease1/vqseg/version_1/checkpoints/epoch=294-step=7079.ckpt')['state_dict'])\n",
    "qnet = qnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def VQgenerate_TTA_results(name, data, noise_type='gauss', base_path='.'):\n",
    "    nTTAs = 100\n",
    "    zdata = {}\n",
    "    \n",
    "    assert noise_type in ['gauss', 's&p', 'poisson', 'speckle'], 'invalid noise_type'\n",
    "    \n",
    "    noise_threshold_list = [0.0, 0.01, 0.1, 0.5, 0.75]\n",
    "    \n",
    "    for noise_threshold in noise_threshold_list:\n",
    "        embs = []; recons = []; emb_losses = []\n",
    "        for _ in range(nTTAs):\n",
    "            x = data['image'][:1, ...].numpy()\n",
    "            dtype = data['image'].dtype\n",
    "            x = noisy(noise_type, x, noise_threshold)\n",
    "            x = torch.tensor(x).type(dtype).cuda() \n",
    "            with torch.no_grad():\n",
    "                x, emb_loss, encoding = qnet._model(x)\n",
    "            embs.append(encoding)\n",
    "            recons.append(x)\n",
    "            emb_losses.append(emb_loss)\n",
    "\n",
    "        embs = torch.cat(embs, 0)\n",
    "        emb_losses = torch.cat(emb_losses, 0)\n",
    "        recons = torch.cat(recons, 0)\n",
    "        recons = torch.argmax(recons, 1)\n",
    "        \n",
    "        zdata[noise_threshold] = {'emb': embs.cpu().numpy(),\n",
    "                                      'emb_loss': emb_losses.cpu().numpy(),\n",
    "                                      'recon': recons.cpu().squeeze().numpy(), \n",
    "                                      'img': data['image'][:1, ...].squeeze().numpy(), \n",
    "                                      'label': data['label'][:1, ...].squeeze().numpy()}\n",
    "\n",
    "    base_path = os.path.join(base_path, noise_type)\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    with open(os.path.join(base_path,'{}.pickle'.format(name)), 'wb') as file:\n",
    "        pickle.dump(zdata, file)\n",
    "    return zdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_zqdata = {}\n",
    "for i in tqdm(range(100)):\n",
    "    data = next(iter(val_dataloader))\n",
    "    all_zqdata[i] = {}\n",
    "    all_zqdata[i]['gauss'] = VQgenerate_TTA_results('image{}'.format(i), data, 'gauss', 'ABDCT/VQNet')\n",
    "    all_zqdata[i]['s&p'] = VQgenerate_TTA_results('image{}'.format(i), data, 's&p', 'ABDCT/VQNet')\n",
    "    all_zqdata[i]['poisson'] = VQgenerate_TTA_results('image{}'.format(i), data, 'poisson', 'ABDCT/VQNet')\n",
    "    all_zqdata[i]['speckle'] = VQgenerate_TTA_results('image{}'.format(i), data, 'speckle', 'ABDCT/VQNet')\n",
    "    \n",
    "with open('all_data_ABDCT_VQNet.pickle', 'wb') as file:\n",
    "        pickle.dump(all_zqdata, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zqdata[0.01]['emb'].shape, zdata[0.01]['emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for noise_threshold in noise_threshold_list:\n",
    "    print (\"============================ noise: {} ===========\".format(noise_threshold))\n",
    "    z, zq = zdata[noise_threshold]['emb'], zqdata[noise_threshold]['emb']\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 0,0,0], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 0,0,0], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 1, 1], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 1, 1], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 0, 1], cmap='coolwarm')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 0, 1], cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(z[:, :, 1, 0, 0], cmap='coolwarm')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(zq[:, :, 1, 0, 0], cmap='coolwarm')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dice = lambda p, l: np.mean([2*(p == i)*(l == i)/((p==i) + (l ==i) + 1e-3) for i in np.unique(l)])\n",
    "import pandas as pd\n",
    "\n",
    "def _draw_(dict_info, noise_type='gauss', base_dir= '.'):\n",
    "    nimgs = len(dict_info.keys())\n",
    "    test_ = dict_info[0][noise_type]\n",
    "    noise_threshold_list = list(test_.keys())\n",
    "    \n",
    "    test_embs = test_[noise_threshold_list[0]]['emb'] # nttas, ...\n",
    "    nttas = test_embs.shape[0]\n",
    "    z_dim = np.prod(test_embs.shape[1:])\n",
    "    \n",
    "    \n",
    "    dice_scores_x = []\n",
    "    dice_scores_y = []\n",
    "    categories = []\n",
    "    \n",
    "    for ni, noise_threshold in enumerate(noise_threshold_list):\n",
    "        \n",
    "            \n",
    "        result_img = np.zeros((nimgs, z_dim))\n",
    "        \n",
    "        for iimg in range(nimgs):\n",
    "            z = dict_info[iimg][noise_type][noise_threshold]['emb'].reshape(nttas, -1)\n",
    "            z = (z - z.min())/(z.max() - z.min())\n",
    "            \n",
    "            result_img[iimgs, :] = np.var(z, axis=0).T\n",
    "            \n",
    "            if noise_threshold == 0.0:\n",
    "                dice_scores_x.append(np.mean([mean_dice(dict_info[iimg][noise_type][noise_threshold]['recon'][itta, ...], \n",
    "                                                    dict_info[iimg][noise_type][noise_threshold]['label']) \\\n",
    "                                                      for itta in range(nttas)]))\n",
    "            else:\n",
    "                dice_scores_y.append(np.mean([mean_dice(dict_info[iimg][noise_type][noise_threshold]['recon'][itta, ...], \n",
    "                                                    dict_info[iimg][noise_type][noise_threshold]['label']) \\\n",
    "                                                      for itta in range(nttas)]))\n",
    "                \n",
    "                categories.append('Noise Threshold: {}'.format(noise_threshold))\n",
    "                \n",
    "        \n",
    "        base_path = os.path.join(base_path, noise_type)\n",
    "        base_path = os.path.join(base_path, 'plots')\n",
    "        os.makedirs(base_path, exist_ok=True)\n",
    "        \n",
    "        plt.figure(figsize=(1, 10))\n",
    "        plt.imshow(result_img, cmap='coolwarm', vmin=0, vmax=1)\n",
    "        plt.axis (‘off’)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(base_path, 'NoiseT{}_NoiseType{}.png'.format(noise_threshold, noise_type)))\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    df['actual-dice'] = dice_scores_x * (len(noise_threshold_list) - 2)\n",
    "    df['perturbed- dice'] = dice_scores_y\n",
    "    df['categories'] = categories\n",
    "\n",
    "    p = sns.jointplot(data=df, x='actual-dice', y='perturbed- dice',  hue=\"categories\", alpha=0.5)\n",
    "    p.plot_joint(sns.kdeplot, levels=20)\n",
    "    p.fig.suptitle(\"aligned latent vectors\")\n",
    "    p.fig.tight_layout()\n",
    "    p.fig.subplots_adjust(top=0.95)\n",
    "    plt.savefig(os.path.join(base_path, 'dice_score_distribution_{}.png'.format(noise_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_data_ABDCT_UNet.pickle', 'rb') as file:\n",
    "    dict_info = pickle.load(file)\n",
    "    \n",
    "_draw_(dict_info, 'gauss', 'ABDCT/VQNet')\n",
    "_draw_(dict_info, 's&p', 'ABDCT/VQNet')\n",
    "_draw_(dict_info, 'poisson', 'ABDCT/VQNet')\n",
    "_draw_(dict_info, 'speckle', 'ABDCT/VQNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_data_ABDCT_VQNet.pickle', 'rb') as file:\n",
    "    dict_info = pickle.load(file)\n",
    "    \n",
    "_draw_(dict_info, 'gauss', 'ABDCT/VQNet')\n",
    "_draw_(dict_info, 's&p', 'ABDCT/VQNet')\n",
    "_draw_(dict_info, 'poisson', 'ABDCT/VQNet')\n",
    "_draw_(dict_info, 'speckle', 'ABDCT/VQNet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
